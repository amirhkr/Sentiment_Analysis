{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/uqhkamel/Downloads/Sentiment_Analysis/venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertTokenizer\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import pandas as pd\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"data/Restaurant_Reviews.tsv\",delimiter='\\t')\n",
    "\n",
    "\n",
    "# Handle missing data\n",
    "df = df.dropna(subset=['Review'])\n",
    "\n",
    "\n",
    "\n",
    "# TMake sure to split the data first before balancing the dataset\n",
    "# Otherise it will be data leakage\n",
    "train_data, test_data = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Liked\n",
       "0    404\n",
       "1    396\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.value_counts('Liked')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Liked\n",
       "0    404\n",
       "1    396\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.value_counts('Liked')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using upsampling tehnique to address imbalanced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the majority and minority classes\n",
    "df_majority = train_data[train_data['Liked'] == 0]  # Majority class\n",
    "df_minority = train_data[train_data['Liked'] == 1]  # Minority class\n",
    "\n",
    "# Oversample the minority class\n",
    "df_minority_over = df_minority.sample(len(df_majority), replace=True)\n",
    "\n",
    "# Combine the majority class with the oversampled minority class\n",
    "df_balanced = pd.concat([df_majority, df_minority_over])\n",
    "\n",
    "# Shuffle the dataset\n",
    "df_balanced = df_balanced.sample(frac=1).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Liked\n",
       "0    404\n",
       "1    404\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_balanced.value_counts('Liked')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Liked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The selection was probably the worst I've seen...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I miss it and wish they had one in Philadelphia!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AN HOUR... seriously?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What I really like there is the crepe station.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This place has it!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>803</th>\n",
       "      <td>Food was really good and I got full petty fast.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>804</th>\n",
       "      <td>I mean really, how do you get so famous for yo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>805</th>\n",
       "      <td>We ordered the duck rare and it was pink and t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>806</th>\n",
       "      <td>The fries were not hot, and neither was my bur...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>807</th>\n",
       "      <td>I don't recommend unless your car breaks down ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>808 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Review  Liked\n",
       "0    The selection was probably the worst I've seen...      0\n",
       "1     I miss it and wish they had one in Philadelphia!      1\n",
       "2                                AN HOUR... seriously?      0\n",
       "3       What I really like there is the crepe station.      1\n",
       "4                                   This place has it!      1\n",
       "..                                                 ...    ...\n",
       "803    Food was really good and I got full petty fast.      1\n",
       "804  I mean really, how do you get so famous for yo...      0\n",
       "805  We ordered the duck rare and it was pink and t...      1\n",
       "806  The fries were not hot, and neither was my bur...      0\n",
       "807  I don't recommend unless your car breaks down ...      0\n",
       "\n",
       "[808 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertTokenizer\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertModel, AdamW, get_linear_schedule_with_warmup\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Initialize BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "class ReviewDataset(Dataset):\n",
    "    def __init__(self, reviews, labels, tokenizer, max_len):\n",
    "        self.reviews = reviews\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.reviews)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        review = str(self.reviews[index])\n",
    "        label = self.labels[index]\n",
    "        \n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            review,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            return_token_type_ids=False,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt',\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'review_text': review,\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'label': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "# Create Dataloaders\n",
    "def create_data_loader(data, tokenizer, max_len, batch_size):\n",
    "    ds = ReviewDataset(\n",
    "        reviews=data.Review.to_numpy(),\n",
    "        labels=data.Liked.to_numpy(),\n",
    "        tokenizer=tokenizer,\n",
    "        max_len=max_len\n",
    "    )\n",
    "    return DataLoader(ds, batch_size=batch_size, num_workers=0)\n",
    "\n",
    "MAX_LEN = 128\n",
    "BATCH_SIZE = 16\n",
    "train_data_loader = create_data_loader(train_data, tokenizer, MAX_LEN, BATCH_SIZE)\n",
    "val_data_loader = create_data_loader(test_data, tokenizer, MAX_LEN, BATCH_SIZE)\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "Train loss: 0.5265, Train accuracy: 0.7488\n",
      "Val loss: 0.3381, Val accuracy: 0.8900\n",
      "Precision: 0.8900, Recall: 0.8900, F1-Score: 0.8900\n",
      "Epoch 2/3\n",
      "Train loss: 0.2547, Train accuracy: 0.9213\n",
      "Val loss: 0.2630, Val accuracy: 0.8950\n",
      "Precision: 0.8962, Recall: 0.8950, F1-Score: 0.8950\n",
      "Epoch 3/3\n",
      "Train loss: 0.1770, Train accuracy: 0.9513\n",
      "Val loss: 0.2558, Val accuracy: 0.9000\n",
      "Precision: 0.9008, Recall: 0.9000, F1-Score: 0.9000\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import BertModel, get_linear_schedule_with_warmup\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "EPOCHS = 3\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch.optim import AdamW\n",
    "\n",
    "class SentimentClassifier(nn.Module):\n",
    "    def __init__(self, n_classes):\n",
    "        super(SentimentClassifier, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "        self.drop = nn.Dropout(p=0.3)\n",
    "        self.out = nn.Linear(self.bert.config.hidden_size, n_classes)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        # BERT returns a tuple: (last_hidden_state, pooled_output)\n",
    "        outputs = self.bert(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask\n",
    "        )\n",
    "        pooled_output = outputs[1]  # Extract the pooled_output (i.e., the [CLS] token representation)\n",
    "\n",
    "        output = self.drop(pooled_output)  # Apply dropout to the pooled output\n",
    "        return self.out(output)\n",
    "\n",
    "\n",
    "model = SentimentClassifier(n_classes=2)\n",
    "model = model.to(device)\n",
    "\n",
    "# Optimizer and loss function\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "loss_fn = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "# Scheduler\n",
    "total_steps = len(train_data_loader) * EPOCHS\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer, num_warmup_steps=0, num_training_steps=total_steps\n",
    ")\n",
    "\n",
    "# Training loop\n",
    "def train_epoch(model, data_loader, loss_fn, optimizer, device, scheduler, n_examples):\n",
    "    model = model.train()\n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "    \n",
    "    for batch in data_loader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "        \n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        _, preds = torch.max(outputs, dim=1)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        \n",
    "        correct_predictions += torch.sum(preds == labels)\n",
    "        losses.append(loss.item())\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    return correct_predictions.double() / n_examples, np.mean(losses)\n",
    "\n",
    "# Validation loop\n",
    "# def eval_model(model, data_loader, loss_fn, device, n_examples):\n",
    "#     model = model.eval()\n",
    "#     losses = []\n",
    "#     correct_predictions = 0\n",
    "    \n",
    "#     with torch.no_grad():\n",
    "#         for batch in data_loader:\n",
    "#             input_ids = batch['input_ids'].to(device)\n",
    "#             attention_mask = batch['attention_mask'].to(device)\n",
    "#             labels = batch['label'].to(device)\n",
    "            \n",
    "#             outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "#             _, preds = torch.max(outputs, dim=1)\n",
    "            \n",
    "#             loss = loss_fn(outputs, labels)\n",
    "#             correct_predictions += torch.sum(preds == labels)\n",
    "#             losses.append(loss.item())\n",
    "\n",
    "#     return correct_predictions.double() / n_examples, np.mean(losses)\n",
    "\n",
    "\n",
    "def eval_model(model, data_loader, loss_fn, device, n_examples):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():  # No gradient calculations in evaluation\n",
    "        for batch in data_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            _, preds = torch.max(outputs, dim=1)\n",
    "\n",
    "            # Calculate loss\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            losses.append(loss.item())\n",
    "            correct_predictions += torch.sum(preds == labels).item()\n",
    "\n",
    "            # Collect predictions and true labels for metrics\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    avg_loss = sum(losses) / len(losses)  # Average loss\n",
    "    accuracy = correct_predictions / n_examples  # Calculate accuracy\n",
    "\n",
    "    # Calculate precision, recall, and F1 score\n",
    "    precision = precision_score(all_labels, all_preds, average='weighted')\n",
    "    recall = recall_score(all_labels, all_preds, average='weighted')\n",
    "    f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "\n",
    "    return accuracy, avg_loss, precision, recall, f1\n",
    "\n",
    "# Training the model\n",
    "\n",
    "history = {'train_acc': [], 'train_loss': [], 'val_acc': [], 'val_loss': []}\n",
    "\n",
    "\n",
    "# for epoch in range(EPOCHS):\n",
    "#     train_acc, train_loss = train_epoch(model, train_data_loader, loss_fn, optimizer, device, scheduler, len(train_data))\n",
    "#     val_acc, val_loss = eval_model(model, val_data_loader, loss_fn, device, len(test_data))\n",
    "    \n",
    "#     history['train_acc'].append(train_acc)\n",
    "#     history['train_loss'].append(train_loss)\n",
    "#     history['val_acc'].append(val_acc)\n",
    "#     history['val_loss'].append(val_loss)\n",
    "\n",
    "#     print(f'Epoch {epoch + 1}/{EPOCHS}')\n",
    "#     print(f'Train loss {train_loss} accuracy {train_acc}')\n",
    "#     print(f'Val loss {val_loss} accuracy {val_acc}')\n",
    "history = []\n",
    "# Training Loop\n",
    "for epoch in range(EPOCHS):\n",
    "    train_acc, train_loss = train_epoch(model, train_data_loader, loss_fn, optimizer, device, scheduler, len(train_data))\n",
    "    val_acc, val_loss, precision, recall, f1 = eval_model(model, val_data_loader, loss_fn, device, len(val_data_loader.dataset))\n",
    "    \n",
    "    # history['train_acc'].append(train_acc)\n",
    "    # history['train_loss'].append(train_loss)\n",
    "    # history['accuracy'].append(val_acc)\n",
    "    # history['loss'].append(val_loss)\n",
    "    # history['precision'].append(precision)\n",
    "    # history['recall'].append(recall)\n",
    "    # history['f1'].append(f1)\n",
    "\n",
    "    print(f'Epoch {epoch + 1}/{EPOCHS}')\n",
    "    print(f'Train loss: {train_loss:.4f}, Train accuracy: {train_acc:.4f}')\n",
    "    print(f'Val loss: {val_loss:.4f}, Val accuracy: {val_acc:.4f}')\n",
    "    print(f'Precision: {precision:.4f}, Recall: {recall:.4f}, F1-Score: {f1:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# Save the model\n",
    "\n",
    "torch.save(model, 'model.pth')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
